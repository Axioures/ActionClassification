
paths:
    root: /home/nick/Desktop/Experiments_ActionClassif
    db: /home/nick/Videos/Hollywood2/AVIClips
    db_data: /home/nick/Dropbox/Gesture/data/ClipSets
    code: /home/nick/Dropbox/Gesture/Code_final
    yael: /home/nick/ExternalPackages/yael_v438/matlab
    LibSvm: /home/nick/ExternalPackages/libsvm-3.17_with_conversion_tool/matlab/

DEBUG: 0
dbName: Hollywood2
global_seed: 25

# feature parameters
features:
    type: DT
    executable: /home/nick/ExternalPackages/dense_trajectory_release_v1.2/release/DenseTrack
    libs: /home/nick/ExternalPackages/ffmpeg/ffmpeg_build/lib/
    descriptors: [Traj, HOG, HOF, MBHx, MBHy, MBH]
    L: 15 # trajectory length
    W: 5 # sampling stride
    N: 32 # neighbourhood size
    s: 2 # number of spatial cells
    t: 3 # number of temporal cells
    save2disk: 1
    # the following flag is experimental, use only with Hollywood2 dataset, and not in a parfor loop!
    use_disk: 0
    
# encoding parameters
encoding:
    type: BoVW # possible options are BoVW, vlad or fisher
    K: 4000 # number of visual words for either kmeans or gmm
    data_usage: 100000 # data used for codebook generation as percentage of TrainData
    pca_factor: 1
    num_seeds: 1 # number of k-means repetitions with different (random) initializations (seeds)

# spatio-temporal pyramids parameters    
#grids:
    #- {h: 1, v: 1, t: 1}
    #- {h: 3, v: 1, t: 1}
    #- {h: 2, v: 2, t: 1}
    #- {h: 1, v: 1, t: 2}
    #- {h: 3, v: 1, t: 2}
    #- {h: 2, v: 2, t: 2}

# classification parameters
classification:
    svm_cost: 100
    kernel: ChiSquared
    combine: 1
    combine_descriptors: [Traj, HOG, HOF, MBHx, MBHy]
    
# possible reusage of elements
reuse:
    features: 1
    # features_path: 

## states
# 0: nothing has been done
# 1: codebook has been generated
# 2: encodings have been computed
# 2.5: kernels have been computed (does not apply to Linear kernel)
# 3: SVMs have been trained
# 4: testinghas been done
state: 1

