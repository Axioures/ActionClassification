
paths:
    root: /rmt8/mobot/experiments/nikos
    db: /rmt8/databases/Hollywood2/AVIClips/
    db_data: /rmt8/databases/Hollywood2/ClipSets/
    code: /home/nick/action_nick/Code_v0.2/
    yael: /rmt8/mobot/external_packages/yael/yael_v438/matlab
    LibSvm: /rmt8/mobot/external_packages/libsvm-3.17/matlab/

DEBUG: 0
dbName: Hollywood2
global_seed: 25

# feature parameters
features:
    type: dense
    executable: /rmt8/mobot/external_packages/stip-2.0-linux/bin/stipdet
    libs: /rmt8/mobot/external_packages/opencv/lib/:/rmt8/mobot/external_packages/ffmpeg/ffmpeg_build/lib/ 
    descriptors: [HOG, HOF, HOGHOF]
    nplev: 3 # number of scales
    plev0: 0 # first scale
    szf: 18 # patch size's spatial factor
    tzf: 4 # patch size's temporal factor
    save2disk: 0
    # the following flag is experimental, use only with Hollywood2 dataset, and not in a parfor loop!
    use_disk: 1
    
# encoding parameters
encoding:
    type: BoVW # possible options are BoVW, vlad or fisher
    K: 4000 # number of visual words for either kmeans or gmm
    data_usage: 100000 # data used for codebook generation as percentage of TrainData
    pca_factor: 1
    num_seeds: 1 # number of k-means repetitions with different (random) initializations (seeds)

# spatio-temporal pyramids parameters    
#grids:
    #- {h: 1, v: 1, t: 1}
    #- {h: 3, v: 1, t: 1}
    #- {h: 2, v: 2, t: 1}
    #- {h: 1, v: 1, t: 2}
    #- {h: 3, v: 1, t: 2}
    #- {h: 2, v: 2, t: 2}

# classification parameters
classification:
    svm_cost: 100
    kernel: ChiSquared
    combine: 0
    
# possible reusage of elements
reuse:
    features: 1
    # features_path: 

## states
# 0: nothing has been done
# 1: codebook has been generated
# 2: encodings have been computed
# 2.5: kernels have been computed (does not apply to Linear kernel)
# 3: SVMs have been trained
# 4: testinghas been done
state: 1

